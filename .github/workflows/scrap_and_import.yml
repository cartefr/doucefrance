name: Scrape and Insert Daily

on:
  schedule:
    - cron: '*/10 * * * *'  # Ex√©cute toutes les 5 min
  workflow_dispatch:

concurrency:
  group: "scrape-and-insert-daily"
  cancel-in-progress: true

jobs:
  scrape-and-insert:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraping and insertion
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          python scrape_and_insert.py --cities "cities.csv" --popular-cities "popular_cities.csv"
